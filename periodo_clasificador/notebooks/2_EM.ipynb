{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a3af3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manejo de datos\n",
    "import pandas as pd \n",
    "#Manejo de tensores \n",
    "import numpy as np\n",
    "#Optimizacion y validacion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "#Baggin\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#Modelos lineales \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Modelos no lineales\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier, RandomForestClassifier \n",
    "from xgboost import XGBRFClassifier\n",
    "#Metricas\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#Preprocesadores\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#Pipline \n",
    "from sklearn.pipeline import Pipeline\n",
    "#Resampleo\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d32be08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>aprueba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob     Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home  teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home    other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences G1 G2 aprueba  \n",
       "0      4        3      4     1     1      3        6  5  6       0  \n",
       "1      5        3      3     1     1      3        4  5  5       0  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargar los datos \n",
    "df = pd.read_csv('../data/student_new.csv')\n",
    "#Visualizarlos para comprobar\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d5bb1",
   "metadata": {},
   "source": [
    "# **Preparación de variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c96d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccion de las variables y separacion de sets para validar luego \n",
    "X = df.drop('aprueba', axis=1)\n",
    "y = df['aprueba']\n",
    "\n",
    "#Separacion\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify=y)\n",
    "\n",
    "#Para modelos lineales \n",
    "X_train_lineal = X_train[['G1', 'G2']]\n",
    "X_test_lineal = X_test[['G1', 'G2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d314ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos resampleados \n",
    "\"\"\"---------------------------------------------------Lineales---------------------------------------------------------------\"\"\"\n",
    "resampler_lineal = SMOTE(random_state=42)\n",
    "X_train_smote, Y_train_smote = resampler_lineal.fit_resample(X_train_lineal, Y_train)\n",
    "\"\"\"---------------------------------------------------No Lineales---------------------------------------------------------------\"\"\"\n",
    "resampler_no_lineal = RandomOverSampler(random_state=42)\n",
    "X_train_over, Y_train_over = resampler_no_lineal.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d74d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribucion de Y_train_smote\n",
      "aprueba\n",
      "0    212\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "Total: 424\n",
      "======================================================================\n",
      "Distribucion de Y_train_over\n",
      "aprueba\n",
      "0    212\n",
      "1    212\n",
      "Name: count, dtype: int64\n",
      "Total: 424\n"
     ]
    }
   ],
   "source": [
    "print('Distribucion de Y_train_smote')\n",
    "print(Y_train_smote.value_counts())\n",
    "print(f'Total: {Y_train_smote.value_counts()[0] + Y_train_smote.value_counts()[1]}')\n",
    "print('=' * 70)\n",
    "print('Distribucion de Y_train_over')\n",
    "print(Y_train_over.value_counts())\n",
    "print(f'Total: {Y_train_over.value_counts()[0] + Y_train_over.value_counts()[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e5ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Varibles numericas y categoricas\n",
    "numericas = X.select_dtypes(include=[np.number]).columns\n",
    "categoricas = X.select_dtypes(exclude=[np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12bb5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear transformador para las variables categoricas \n",
    "transformer = ColumnTransformer(transformers=[\n",
    "    ('num', 'passthrough', numericas),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categoricas)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d40ed",
   "metadata": {},
   "source": [
    "# **Creación de modelos y funciones entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "446516f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"---------------------------------------------------Lineales---------------------------------------------------------------\"\"\"\n",
    "modelos_lineales = {\n",
    "    'baggin_logistic': BaggingClassifier(LogisticRegression(penalty='l1', solver='liblinear', C=1.0, max_iter=1000, random_state=42)),\n",
    "    'LogisticRegression': LogisticRegression(penalty='l2', solver='lbfgs', C=1.0, max_iter=1000,random_state=42),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier()\n",
    "}\n",
    "\"\"\"---------------------------------------------------No Lineales---------------------------------------------------------------\"\"\"\n",
    "modelos_no_lineales = {\n",
    "    'DecisionTreeClassifier':DecisionTreeClassifier(max_depth=2, random_state=42),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(max_depth=5, random_state=42, splitter='best'),\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=42, n_estimators=50, max_depth=5),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=3, random_state=42),\n",
    "    'XGBRFClassifier': XGBRFClassifier(n_estimators=100, learning_rate=1.0, subsample=0.8, random_state=42),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(estimator=DecisionTreeClassifier(), learning_rate=1.0, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1710507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_entrenamiento(datos_train:list, datos_test:list, ln_models: dict, unl_models:dict):\n",
    "    \"\"\"\n",
    "    En esta funcion se encarga de entrenar los modelos de manera iterativa realizando predicciones y metricas\n",
    "    para poder evaluar los modelos. Itera por cada uno de los modelos creando un pipeline que pueda tener \n",
    "    el preprocesador y el modelo. Finalmente se entrena y realiza las pruebas para las metricas guardandolas\n",
    "    en un diccionario con el nombre del modelo y los resultados en una lista. Hace eso por cada iteracion\n",
    "    y con los dos tipos de modelos , lieales y no lineales\n",
    "\n",
    "    Parametros: \n",
    "    datos_train: Una lista que devuelve los datos para entrenar tanto lineales como no lineales \n",
    "    datos_test: Una lista que devuelde datos de testeo lineales y no lineales \n",
    "    ln_models:Devuelve un diccionario con modelos lineales\n",
    "    unl_models:Devuelve un diccionario con modelos no lineales\n",
    "\n",
    "    retur: dos diccionarios con los resultados lineales y no lineales\n",
    "    \"\"\"\n",
    "    \n",
    "    #Resultados obtenidos\n",
    "    resultados_lineales = {}\n",
    "    resultados_unlineales = {}\n",
    "\n",
    "    #---------------------Para modelos lineales -----------------------\n",
    "    print('='*70)\n",
    "    print('🔴 Entrenando los modelos lineales...')\n",
    "    print('='*70)\n",
    "    for nombre, modelo in ln_models.items():\n",
    "        print(f'Modelo {nombre} ha comenzado...')\n",
    "        pipline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', modelo)\n",
    "        ])\n",
    "\n",
    "        pipline.fit(datos_train[0], datos_train[1])\n",
    "        pred = pipline.predict(datos_test[0])\n",
    "        report, matrix_conf, acc =  classification_report(datos_test[2], pred), confusion_matrix(datos_test[2], pred), accuracy_score(datos_test[2], pred)\n",
    "        resultados_lineales[nombre] = [report, matrix_conf, acc]\n",
    "        print(f'Modelo {nombre} ha finalizado')\n",
    "        print('=-'*70)\n",
    "\n",
    "    #---------------------Para modelos no lineales -----------------------\n",
    "    print('='*70)\n",
    "    print('🔵 Entrenando modelos no lineales...')\n",
    "    print('='*70)\n",
    "\n",
    "    for nombre, modelo in unl_models.items():\n",
    "        print(f'Modelo {nombre} ha comenzado...')\n",
    "        pipline = Pipeline([\n",
    "            ('preprocesador', transformer),\n",
    "            ('model', modelo)\n",
    "        ])\n",
    "\n",
    "        pipline.fit(datos_train[2], datos_train[1])\n",
    "        pred = pipline.predict(datos_test[1])\n",
    "        report, matrix_conf, acc = classification_report(datos_test[2], pred), confusion_matrix(datos_test[2], pred), accuracy_score(datos_test[2], pred)\n",
    "        resultados_unlineales[nombre] = [report, matrix_conf, acc]\n",
    "        print(f'Modelo {nombre} ha finalizado.')\n",
    "        print('=-'*70)\n",
    "\n",
    "    return [resultados_lineales, resultados_unlineales]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf0df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🔴 Entrenando los modelos lineales...\n",
      "======================================================================\n",
      "Modelo baggin_logistic ha comenzado...\n",
      "Modelo baggin_logistic ha finalizado\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "Modelo LogisticRegression ha comenzado...\n",
      "Modelo LogisticRegression ha finalizado\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "Modelo KNeighborsClassifier ha comenzado...\n",
      "Modelo KNeighborsClassifier ha finalizado\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "======================================================================\n",
      "🔵 Entrenando modelos no lineales...\n",
      "======================================================================\n",
      "Modelo DecisionTreeClassifier ha comenzado...\n",
      "Modelo DecisionTreeClassifier ha finalizado.\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "Modelo RandomForestClassifier ha comenzado...\n",
      "Modelo RandomForestClassifier ha finalizado.\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "Modelo GradientBoostingClassifier ha comenzado...\n",
      "Modelo GradientBoostingClassifier ha finalizado.\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "Modelo XGBRFClassifier ha comenzado...\n",
      "Modelo XGBRFClassifier ha finalizado.\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "Modelo AdaBoostClassifier ha comenzado...\n",
      "Modelo AdaBoostClassifier ha finalizado.\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n"
     ]
    }
   ],
   "source": [
    "#Listas con datos de entrenamiento y testeo para la funcion\n",
    "lista_train = [X_train_smote, Y_train_smote, X_train_over]\n",
    "lista_test = [X_test_lineal, X_test, Y_test]\n",
    "resultados = funcion_entrenamiento(lista_train, lista_test, modelos_lineales, modelos_no_lineales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e06e51f",
   "metadata": {},
   "source": [
    "# **Funcion de evaluacion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = ['🔴lineales', '🔵no lineales']\n",
    "def eval_fun(resultados, mostrar_info=None):\n",
    "    \"\"\"\n",
    "    Esta funcion se encarga de revisar los diccionarios con resultados de la funcion que se encarga de entrenar \n",
    "    para poder guardarl los modelos superiores a 0.88 de accuracy  guarda los mismos parametros en un diccionario pero solamente\n",
    "    los que pasan por cierto valor\n",
    "    \n",
    "    Parametros: \n",
    "    resultados: devuelve una lista con diccionarios para evaluar\n",
    "    mostrar_info: se encarga de mostrar el contenido o no de los resultados \n",
    "\n",
    "    return un diccionario con los mejores modelos evaluados\n",
    "    \"\"\"\n",
    "    mejores_modelos_accbased = {}\n",
    "    for i, v in enumerate(resultados):\n",
    "        if mostrar_info == True:\n",
    "            print('='*50)\n",
    "            print(f'Modelos: {modelos[i]}')\n",
    "            print('='*50)\n",
    "        for k, v in v.items():\n",
    "            if mostrar_info == True:\n",
    "                print('|'*50)\n",
    "                print(f'Metricas para el modelo {k}')\n",
    "                print(f'Reporte general:\\n {v[0]}')\n",
    "                print(f'Matriz de confusion {v[1]}')\n",
    "            if v[2] >= 0.88:\n",
    "                mejores_modelos_accbased[k] = [v[0], v[1], v[2]]\n",
    "                \n",
    "    return mejores_modelos_accbased\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a56317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Modelos: 🔴lineales\n",
      "==================================================\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Metricas para el modelo baggin_logistic\n",
      "Reporte general:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83        26\n",
      "           1       0.98      0.83      0.90        53\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.86      0.90      0.87        79\n",
      "weighted avg       0.90      0.87      0.88        79\n",
      "\n",
      "Matriz de confusion [[25  1]\n",
      " [ 9 44]]\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Metricas para el modelo LogisticRegression\n",
      "Reporte general:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.79        26\n",
      "           1       0.98      0.77      0.86        53\n",
      "\n",
      "    accuracy                           0.84        79\n",
      "   macro avg       0.83      0.87      0.83        79\n",
      "weighted avg       0.88      0.84      0.84        79\n",
      "\n",
      "Matriz de confusion [[25  1]\n",
      " [12 41]]\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Metricas para el modelo KNeighborsClassifier\n",
      "Reporte general:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84        26\n",
      "           1       0.96      0.87      0.91        53\n",
      "\n",
      "    accuracy                           0.89        79\n",
      "   macro avg       0.87      0.90      0.88        79\n",
      "weighted avg       0.90      0.89      0.89        79\n",
      "\n",
      "Matriz de confusion [[24  2]\n",
      " [ 7 46]]\n",
      "==================================================\n",
      "Modelos: 🔵no lineales\n",
      "==================================================\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Metricas para el modelo DecisionTreeClassifier\n",
      "Reporte general:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80        26\n",
      "           1       0.96      0.81      0.88        53\n",
      "\n",
      "    accuracy                           0.85        79\n",
      "   macro avg       0.83      0.87      0.84        79\n",
      "weighted avg       0.87      0.85      0.85        79\n",
      "\n",
      "Matriz de confusion [[24  2]\n",
      " [10 43]]\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Metricas para el modelo RandomForestClassifier\n",
      "Reporte general:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        26\n",
      "           1       1.00      0.81      0.90        53\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.86      0.91      0.87        79\n",
      "weighted avg       0.91      0.87      0.88        79\n",
      "\n",
      "Matriz de confusion [[26  0]\n",
      " [10 43]]\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Metricas para el modelo GradientBoostingClassifier\n",
      "Reporte general:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84        26\n",
      "           1       0.96      0.87      0.91        53\n",
      "\n",
      "    accuracy                           0.89        79\n",
      "   macro avg       0.87      0.90      0.88        79\n",
      "weighted avg       0.90      0.89      0.89        79\n",
      "\n",
      "Matriz de confusion [[24  2]\n",
      " [ 7 46]]\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Metricas para el modelo XGBRFClassifier\n",
      "Reporte general:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        26\n",
      "           1       1.00      0.81      0.90        53\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.86      0.91      0.87        79\n",
      "weighted avg       0.91      0.87      0.88        79\n",
      "\n",
      "Matriz de confusion [[26  0]\n",
      " [10 43]]\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Metricas para el modelo AdaBoostClassifier\n",
      "Reporte general:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79        26\n",
      "           1       0.94      0.83      0.88        53\n",
      "\n",
      "    accuracy                           0.85        79\n",
      "   macro avg       0.83      0.86      0.84        79\n",
      "weighted avg       0.86      0.85      0.85        79\n",
      "\n",
      "Matriz de confusion [[23  3]\n",
      " [ 9 44]]\n",
      "Mejores modelos dict_keys(['KNeighborsClassifier', 'GradientBoostingClassifier'])\n"
     ]
    }
   ],
   "source": [
    "#Extraer l informacion de lo mejores modelos para tunerlos\n",
    "mejores_modelos = eval_fun(resultados, mostrar_info=True)\n",
    "print(f'Mejores modelos {mejores_modelos.keys()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f78181d",
   "metadata": {},
   "source": [
    "# **Función de busqeuda de parametros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d32b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Piplines a realizar la busqueda\n",
    "pipline_kn = Pipeline([('sacaler', StandardScaler()), ('model_kn', KNeighborsClassifier())])\n",
    "pipline_grad = Pipeline([('proprocesador', transformer), ('model_grad', GradientBoostingClassifier(random_state=42))])\n",
    "#Plantillas pra los Buscadores\n",
    "plantillas = [{'KNeighborsClassifier':{\n",
    "    'model_kn__n_neighbors': [3, 5, 7, 9, 11, 13, 15],         # número de vecinos\n",
    "    'model_kn__weights': ['uniform', 'distance'],    # tipo de ponderación\n",
    "    'model_kn__metric': ['euclidean', 'manhattan', 'minkowski'], # métrica de distancia\n",
    "    'model_kn__p': [1, 2]                            # 1=Manhattan, 2=Euclidiana\n",
    "}}, {'GradientBoostingClassifier':{\n",
    "    'model_grad__n_estimators': [50, 100, 150, 200],     # número de árboles\n",
    "    'model_grad__learning_rate': [0.01, 0.05, 0.1],  # tasa de aprendizaje\n",
    "    'model_grad__max_depth': [2, 3, 4, 5],           # profundidad máxima\n",
    "    'model_grad__min_samples_split': [2, 4, 6],  # mínimo para dividir nodo\n",
    "    'model_grad__min_samples_leaf': [1, 2, 3],    # mínimo por hoja\n",
    "    'model_grad__subsample': [0.7, 0.8, 1.0],       # muestreo del dataset\n",
    "    'model_grad__max_features': ['sqrt', 'log2'] # características por árbol\n",
    "}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busquedahyper(x_train_l,  x_train_n, y_train_l, y_train_n, modelos:list, verbose=False):\n",
    "    \"\"\"\n",
    "    Obtiene los mejores modelos y se encarga de realizar una busqueda de hyper parametros\n",
    "    de manera simultanea iterando por cada uno de ellos accediendo tambien a un diccionario\n",
    "    con los modelos para poder utilizarlos en el buscador. Filtra para que se ajuste a los datos\n",
    "    dependiendo el modelo que se tiene para que sea entrenado con datos lineales o no lineales\n",
    "\n",
    "    Parametros: \n",
    "    x_train_l,  x_train_n, y_train_l, y_train_n: Son los datos de entrenamientos lineales y no lineales de los mehjores modelos\n",
    "    modelos: una lista con diccionarios de los hyperparemtros a combinar \n",
    "    vebose:  booleano que se encarga de activar monitoreo(mensajes) durante el entrenamiento para poder ver como va (opcionalidad)\n",
    "\n",
    "    return: Se encarga de devolverme una lista con dos lista con diccionarios los cuales tienen el nombre del modelo con sus \n",
    "    mejores parametros y mejor metrica de evaluacion\n",
    "    \"\"\"\n",
    "    mejores_params = []\n",
    "    mejores_resultados = []\n",
    "    lineales = ['KNeighborsClassifier']\n",
    "    pipelines = {\n",
    "        'KNeighborsClassifier':pipline_kn,\n",
    "        'GradientBoostingClassifier': pipline_grad\n",
    "    }\n",
    "    \n",
    "    for i in modelos:\n",
    "        for k, v in i.items():\n",
    "            print('-'*50)\n",
    "            print(f'Iniciando busqueda para: {k}')\n",
    "            \n",
    "            pipe = pipelines[k]\n",
    "\n",
    "            search = GridSearchCV(\n",
    "                estimator=pipe,\n",
    "                param_grid=v,\n",
    "                scoring='f1',\n",
    "                cv=5,\n",
    "                verbose=1 if verbose else 0\n",
    "            )\n",
    "            if k == lineales:\n",
    "                search.fit(x_train_l, y_train_l)\n",
    "            else:\n",
    "                search.fit(x_train_n, y_train_n)\n",
    "            \n",
    "            mejores_params.append({k: search.best_params_})\n",
    "            mejores_resultados.append({k: search.best_score_})\n",
    "\n",
    "            print('-'*50)\n",
    "            print(f'Finalizando busqueda para: {k}')\n",
    "\n",
    "    return [mejores_params, mejores_resultados]\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ddc8fc",
   "metadata": {},
   "source": [
    "# **Seleccion del mejor modelo y validación** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59055672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Iniciando busqueda para: KNeighborsClassifier\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Iniciando busqueda para: GradientBoostingClassifier\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "#Instanciar los resultados \n",
    "resultados = busquedahyper(X_train_smote, X_train_over, Y_train_smote, Y_train_over, plantillas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069386d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'KNeighborsClassifier': {'model_kn__metric': 'euclidean',\n",
       "    'model_kn__n_neighbors': 15,\n",
       "    'model_kn__p': 1,\n",
       "    'model_kn__weights': 'uniform'}},\n",
       "  {'GradientBoostingClassifier': {'model_grad__learning_rate': 0.1,\n",
       "    'model_grad__max_depth': 4,\n",
       "    'model_grad__max_features': 'sqrt',\n",
       "    'model_grad__min_samples_leaf': 3,\n",
       "    'model_grad__min_samples_split': 2,\n",
       "    'model_grad__n_estimators': 200,\n",
       "    'model_grad__subsample': 1.0}}],\n",
       " [{'KNeighborsClassifier': np.float64(0.9319143514002721)},\n",
       "  {'GradientBoostingClassifier': np.float64(0.963112080275148)}]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Revisar los resultados de los parametros y metricas obetenidas\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd8ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para TEST:\n",
      "\n",
      " Reporte general: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83        26\n",
      "           1       0.98      0.83      0.90        53\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.86      0.90      0.87        79\n",
      "weighted avg       0.90      0.87      0.88        79\n",
      " \n",
      "\n",
      " Matriz de confusión: \n",
      "\n",
      " [[25  1]\n",
      " [ 9 44]] \n",
      "\n",
      " Accuracy: \n",
      "\n",
      " 0.8734177215189873 \n",
      "\n",
      "\n",
      "Para TRAIN: \n",
      "\n",
      " Reporte general: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       212\n",
      "           1       0.95      0.92      0.94       212\n",
      "\n",
      "    accuracy                           0.94       424\n",
      "   macro avg       0.94      0.94      0.94       424\n",
      "weighted avg       0.94      0.94      0.94       424\n",
      " \n",
      "\n",
      " Matriz de confusión: \n",
      "\n",
      " [[202  10]\n",
      " [ 17 195]] \n",
      "\n",
      " Accuracy: \n",
      "\n",
      " 0.9363207547169812\n"
     ]
    }
   ],
   "source": [
    "#Probar pipline con los parametros sugeridos\n",
    "pipline_kn = Pipeline([('preprocesador', StandardScaler()), ('model', KNeighborsClassifier(n_neighbors=15, p=1, weights='uniform'))])\n",
    "#Prediccion para el modelo\n",
    "pipline_kn.fit(X_train_smote, Y_train_smote)\n",
    "pred = pipline_kn.predict(X_test_lineal)\n",
    "#Metricas para test\n",
    "report, cf, acc = classification_report(Y_test, pred), confusion_matrix(Y_test, pred), accuracy_score(Y_test, pred)\n",
    "print(f'Para TEST:\\n\\n Reporte general: \\n\\n {report} \\n\\n Matriz de confusión: \\n\\n {cf} \\n\\n Accuracy: \\n\\n {acc} \\n\\n')\n",
    "#Metricas para train\n",
    "pred = pipline_kn.predict(X_train_smote)\n",
    "report, cf, acc = classification_report(Y_train_smote, pred), confusion_matrix(Y_train_smote, pred), accuracy_score(Y_train_smote, pred)\n",
    "print(f'Para TRAIN: \\n\\n Reporte general: \\n\\n {report} \\n\\n Matriz de confusión: \\n\\n {cf} \\n\\n Accuracy: \\n\\n {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e101d079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para TEST:\n",
      "\n",
      " Reporte general: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83        26\n",
      "           1       0.98      0.83      0.90        53\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.86      0.90      0.87        79\n",
      "weighted avg       0.90      0.87      0.88        79\n",
      " \n",
      "\n",
      " Matriz de confusión: \n",
      "\n",
      " [[25  1]\n",
      " [ 9 44]] \n",
      "\n",
      " Accuracy: \n",
      "\n",
      " 0.8734177215189873 \n",
      "\n",
      "\n",
      "Para TRAIN: \n",
      "\n",
      " Reporte general: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       212\n",
      "           1       0.97      0.93      0.95       212\n",
      "\n",
      "    accuracy                           0.95       424\n",
      "   macro avg       0.95      0.95      0.95       424\n",
      "weighted avg       0.95      0.95      0.95       424\n",
      " \n",
      "\n",
      " Matriz de confusión: \n",
      "\n",
      " [[206   6]\n",
      " [ 14 198]] \n",
      "\n",
      " Accuracy: \n",
      "\n",
      " 0.9528301886792453\n"
     ]
    }
   ],
   "source": [
    "#Probar modelo con los parametros sugeridos \n",
    "pipline_grad = Pipeline([('preprocesador', transformer), ('model', GradientBoostingClassifier(learning_rate=0.01,max_depth=4, max_features='sqrt', min_samples_leaf=3, min_samples_split=2, n_estimators=100, subsample=1.0))])\n",
    "#Prediccion para el modelo\n",
    "pipline_grad.fit(X_train_over, Y_train_over)\n",
    "pred = pipline_grad.predict(X_test)\n",
    "#Metricas para test\n",
    "report, cf, acc = classification_report(Y_test, pred), confusion_matrix(Y_test, pred), accuracy_score(Y_test, pred)\n",
    "print(f'Para TEST:\\n\\n Reporte general: \\n\\n {report} \\n\\n Matriz de confusión: \\n\\n {cf} \\n\\n Accuracy: \\n\\n {acc} \\n\\n')\n",
    "#Metricas para train\n",
    "pred = pipline_grad.predict(X_train_over)\n",
    "report, cf, acc = classification_report(Y_train_over, pred), confusion_matrix(Y_train_over, pred), accuracy_score(Y_train_over, pred)\n",
    "print(f'Para TRAIN: \\n\\n Reporte general: \\n\\n {report} \\n\\n Matriz de confusión: \\n\\n {cf} \\n\\n Accuracy: \\n\\n {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841b593",
   "metadata": {},
   "source": [
    "En el modelo de gradient hubieron ciertos fallos a la hora de poner los hyperparams ya qeu este estaba presentando un fuerte cao de overfitting teniendo accuracy: 1.0 y datos de test mucho mas bajos por lo cual opte por cambiar ciertos parametros como:\n",
    "\n",
    "**learning_rate:** Antes: 0.1 | Ahora: 0.01\n",
    "\n",
    "**Estimators:** Antes: 200  | Ahora: 100\n",
    "\n",
    "Reduciendo el overfitting y obteniendo buena generalizacion pero mas ajustada que el otro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c86d0f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Scores: [0.825      0.9        0.94117647 0.98765432 0.93670886]\n",
      "==================================================\n",
      "Promedio de scores 0.9181079304670765\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#Crear validación cruzada \n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipline_kn, X_train_smote, Y_train_smote, cv=folds, scoring='f1')\n",
    "print('='*50)\n",
    "print(f'Scores: {scores}')\n",
    "print('='*50)\n",
    "print(f'Promedio de scores {np.mean(scores)}')\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfcf74a",
   "metadata": {},
   "source": [
    "# **Modelo seleccionado**\n",
    "\n",
    "El modelo seleccionado fue KNeighborsClassifier este modelo nos da mucha mejor generalizacion y buen performance, gradient si bien es un modelo mas robusto , nos otorgó con los parametros sugeridos por el buscador un overfitting el cual lo reducimos agregando un learning rate mas pequeño y bajando la cantidad de estimadores. Sin embargo para mantener una generalización mucho mejor elijo el modelo lineal con la variables mas correlacionadas y lineal  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
